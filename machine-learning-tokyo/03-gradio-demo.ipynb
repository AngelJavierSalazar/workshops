{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d55fd487-9ea6-4580-98a9-d19d3c1db83d",
   "metadata": {},
   "source": [
    "<!--<badge>--><a href=\"https://colab.research.google.com/github/huggingface/workshops/blob/main/nlp-zurich/03-gradio-demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a><!--</badge>-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c47386",
   "metadata": {},
   "source": [
    "# Creating a Transformers demo with Gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee3a648-2519-4617-a206-19b8c5cfef3d",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* https://huggingface.co/blog/gradio-spaces\n",
    "* https://huggingface.co/blog/gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f793dc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers gradio sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87712d83",
   "metadata": {},
   "source": [
    "## Example 1: Using the Transformers pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efab6bce-f259-4956-98b6-ad379e4fccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce4a01e6-6143-4dec-a560-19498428f01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a6f0abb42943c6b3e009534bfc1ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/976 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb88cf85680464a9589c40c2ad55650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d3ef08befd7489f869ff862e820c43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/398 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5472f4bd11024427b3fd47a71be0f888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24cd301d3caa48419b09c9a1e1a6c53e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b7daf962cb431686cb083f9060f434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = pipeline(\"text-classification\", model=\"lewtun/xlm-roberta-base-finetuned-marc-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9751057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'poor', 'score': 0.43474119901657104}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"The Lord of the Rings is waaay too long to read!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e064676e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('üòª', 0.82918)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2emoji = {\"terrible\": \"üí©\", \"poor\": \"üòæ\", \"ok\": \"üê±\", \"good\": \"üò∫\", \"great\": \"üòª\"}\n",
    "\n",
    "def predict(text):\n",
    "    preds = pipe(text)[0]\n",
    "    return label2emoji[preds[\"label\"]], round(preds[\"score\"], 5)\n",
    "\n",
    "predict(\"I love this soccer ball\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c65091e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally at: http://127.0.0.1:7860/\n",
      "To create a public link, set `share=True` in `launch()`.\n",
      "Interface loading below...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"http://127.0.0.1:7860/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f91cfe354f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/28/k4cy5q7s2hs92xq7_h89_vgm0000gn/T/ipykernel_8585/3598768419.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mgradio_ui\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/huggingface/lib/python3.8/site-packages/gradio/interface.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, inline, inbrowser, share, debug, auth, auth_message, private_endpoint, prevent_thread_lock)\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m         is_in_interactive_mode = bool(\n\u001b[1;32m    629\u001b[0m             getattr(sys, 'ps1', sys.flags.interactive))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gradio_ui = gr.Interface(\n",
    "    fn=predict,\n",
    "    title=\"Predicting review scores from customer reviews\",\n",
    "    description=\"Enter some review text about an Amazon product and check what the model predicts for it's star rating.\",\n",
    "    inputs=[\n",
    "        gr.inputs.Textbox(lines=5, label=\"Paste some text here\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.outputs.Textbox(label=\"Label\"),\n",
    "        gr.outputs.Textbox(label=\"Score\"),\n",
    "    ],\n",
    "    examples=[\n",
    "        [\"My favourite book is Cryptonomicon!\"], [\"ÁßÅ„ÅÆÂ•Ω„Åç„Å™Êú¨„ÅØ„Äå„ÇØ„É™„Éó„Éà„Éé„Éü„Ç≥„É≥„Äç„Åß„Åô\"]\n",
    "    ],\n",
    ")\n",
    "\n",
    "gradio_ui.launch(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4afb5f-6f9b-42ab-881e-34870729d028",
   "metadata": {},
   "source": [
    "## Example 2: Using the Inference API from the Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b440dde-e6e7-4dc0-afc0-79f097360797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceApi\n",
    "\n",
    "text = \"My favourite book is Cryptonomicon!\"\n",
    "inference = InferenceApi(\"lewtun/xlm-roberta-base-finetuned-marc-en\")\n",
    "preds = inference(inputs=text)\n",
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02675d8-95d4-4874-9b30-aa375da20054",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_preds = sorted(preds[0], key=lambda d: d['score'], reverse=True) \n",
    "sorted_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96673a20-fc00-4540-b85d-3cd2696df1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_predict(text):\n",
    "    inference = InferenceApi(\"lewtun/xlm-roberta-base-finetuned-marc-en\")\n",
    "    preds = inference(inputs=text)\n",
    "    sorted_preds = sorted(preds[0], key=lambda d: d['score'], reverse=True)[0]\n",
    "    return label2emoji[sorted_preds[\"label\"]], round(sorted_preds[\"score\"], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8250d8a-6bd1-4406-8a06-3e0de40eebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_predict(\"I love these shoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f756f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradio_ui = gr.Interface.load(\n",
    "    name=\"lewtun/xlm-roberta-base-finetuned-marc\",\n",
    "    src=\"huggingface\",\n",
    "    fn=inference_predict,\n",
    "    title=\"Review analysis\",\n",
    "    description=\"Enter some text and check if model detects it's star rating.\",\n",
    "    inputs=[\n",
    "        gr.inputs.Textbox(lines=5, label=\"Paste some text here\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.outputs.Textbox(label=\"Label\"),\n",
    "        gr.outputs.Textbox(label=\"Score\"),\n",
    "    ],\n",
    "    examples=[\n",
    "        [\"I love these running shoes\"], [\"J'adore ces chaussures de course\"], [\"Ich liebe diese Laufschuhe\"]\n",
    "    ],\n",
    ")\n",
    "\n",
    "gradio_ui.launch(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5193629",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f835d35ef2d7d572ed1f1be271ae903cca02f9a46b282db81c294a2d4ce247b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
